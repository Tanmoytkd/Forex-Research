{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: mysqlclient in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install mysqlclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db2\n",
    "engine = db2.create_engine('mysql://root@localhost/forex')\n",
    "connection = engine.connect()\n",
    "metadata = db2.MetaData()\n",
    "renko = db2.Table('renko', metadata, autoload=True, autoload_with=engine)\n",
    "state_table = db2.Table('state', metadata, autoload=True, autoload_with=engine)\n",
    "# print(price.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows count:  194760745\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_name = 'TickStory/clean/EURUSD.csv'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    head = f.readline()\n",
    "    row = f.readline()\n",
    "\n",
    "file_size = os.path.getsize(file_name)\n",
    "\n",
    "dividant = file_size - len(head)-1 #one negated for /r in the first line\n",
    "divider = len(row)+1 #one added for /r in each line\n",
    "\n",
    "total_line_count = dividant//divider\n",
    "print(\"total rows count: \", total_line_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x000001CE98FE0CC0>\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    passwd=\"\",\n",
    "    database=\"forex\"\n",
    ")\n",
    "\n",
    "print(db) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user(msg):\n",
    "    print(msg)\n",
    "    response = ''\n",
    "    while response.lower() not in {\"yes\", \"no\"}:\n",
    "        response = input(\"Please enter yes or no: \")\n",
    "    return response.lower() == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "class Chart:\n",
    "\n",
    "    def __init__(self, brick_size=0.0025, brick_price=None, previous_timestamp=None, previous_brick_timestamp=None, crossover_brick=False):\n",
    "        self.brick_size = brick_size\n",
    "        self.brick_price = brick_price\n",
    "        self.previous_timestamp = previous_timestamp\n",
    "        self.previous_brick_timestamp = previous_brick_timestamp\n",
    "        self.crossover_brick = crossover_brick\n",
    "\n",
    "    def feed(self, id, price, timestamp):\n",
    "        new_brick = False\n",
    "        price = round(price, 5)\n",
    "        self.previous_timestamp = timestamp if self.previous_timestamp is None else self.previous_timestamp\n",
    "        self.previous_brick_timestamp = timestamp if self.previous_brick_timestamp is None else self.previous_brick_timestamp\n",
    "\n",
    "        self.brick_price = price if self.brick_price is None else self.brick_price\n",
    "\n",
    "        time_difference_between_ticks = timestamp - self.previous_timestamp\n",
    "        if not time_difference_between_ticks.days == 0:\n",
    "            self.crossover_brick = True\n",
    "        else:\n",
    "            self.crossover_brick = False\n",
    "\n",
    "        while price >= self.brick_price + self.brick_size:\n",
    "            #do something\n",
    "            self.brick_price += self.brick_size\n",
    "            self.brick_price = round(self.brick_price, 5)\n",
    "            values = [{'direction':'up',\n",
    "                       'start_price': round(self.brick_price - self.brick_size, 5),\n",
    "                       'close_price': self.brick_price,\n",
    "                       'start_time': self.previous_brick_timestamp, \n",
    "                       'close_time': timestamp}]\n",
    "            query = db2.insert(renko)\n",
    "            connection.execute(query,values)\n",
    "            self.previous_brick_timestamp = timestamp\n",
    "            print(\"up\", self.brick_price, timestamp, self.crossover_brick)\n",
    "            new_brick = True\n",
    "\n",
    "        while price <= self.brick_price - self.brick_size:\n",
    "            #do something\n",
    "            self.brick_price -= self.brick_size\n",
    "            self.brick_price = round(self.brick_price, 5)\n",
    "            values = [{'direction':'down',\n",
    "                       'start_price': round(self.brick_price + self.brick_size, 5),\n",
    "                       'close_price': self.brick_price,\n",
    "                       'start_time': self.previous_brick_timestamp, \n",
    "                       'close_time': timestamp}]\n",
    "            query = db2.insert(renko)\n",
    "            connection.execute(query,values)\n",
    "            self.previous_brick_timestamp = timestamp\n",
    "            print(\"down\", self.brick_price, timestamp, self.crossover_brick)\n",
    "            new_brick = True\n",
    "        \n",
    "        if new_brick==True:\n",
    "            connection.execute(db2.delete(state_table))\n",
    "            state = [{\n",
    "                'id': id,\n",
    "                'brick_size': self.brick_size,\n",
    "                'brick_price': self.brick_price,\n",
    "                'previous_timestamp': self.previous_timestamp,\n",
    "                'previous_brick_timestamp': self.previous_brick_timestamp,\n",
    "                'crossover_brick': self.crossover_brick\n",
    "            }]\n",
    "            connection.execute(db2.insert(state_table), state)\n",
    "\n",
    "\n",
    "        self.previous_timestamp = timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# help(datetime.timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting from 152761984\n",
      "up 1.22868 2018-02-08 07:11:36 False\n",
      "down 1.22618 2018-02-08 08:07:20 False\n",
      "down 1.22368 2018-02-08 08:29:58 False\n",
      "up 1.22618 2018-02-08 13:19:37 False\n",
      "up 1.22868 2018-02-08 14:21:09 False\n",
      "down 1.22618 2018-02-08 15:10:12 False\n",
      "down 1.22368 2018-02-08 16:26:25 False\n",
      "up 1.22618 2018-02-08 18:20:40 False\n",
      "up 1.22868 2018-02-09 07:58:34 False\n",
      "down 1.22618 2018-02-09 08:24:33 False\n",
      "down 1.22368 2018-02-09 11:56:17 False\n",
      "up 1.22618 2018-02-09 13:06:39 False\n",
      "down 1.22368 2018-02-09 15:28:07 False\n",
      "down 1.22118 2018-02-09 17:39:45 False\n",
      "up 1.22368 2018-02-09 19:17:18 False\n",
      "up 1.22618 2018-02-12 00:43:21 False\n",
      "up 1.22868 2018-02-12 03:56:14 False\n",
      "down 1.22618 2018-02-12 08:06:21 False\n",
      "down 1.22368 2018-02-12 13:35:01 False\n",
      "up 1.22618 2018-02-12 14:46:13 False\n",
      "up 1.22868 2018-02-12 18:25:07 False\n",
      "up 1.23118 2018-02-13 05:19:57 False\n",
      "up 1.23368 2018-02-13 08:32:59 False\n",
      "up 1.23618 2018-02-13 14:58:32 False\n",
      "up 1.23868 2018-02-14 03:32:48 False\n",
      "down 1.23618 2018-02-14 08:25:25 False\n",
      "down 1.23368 2018-02-14 13:30:01 False\n",
      "down 1.23118 2018-02-14 13:30:06 False\n",
      "down 1.22868 2018-02-14 13:33:43 False\n",
      "up 1.23118 2018-02-14 13:57:53 False\n",
      "up 1.23368 2018-02-14 15:06:47 False\n",
      "up 1.23618 2018-02-14 15:09:20 False\n",
      "up 1.23868 2018-02-14 15:40:41 False\n",
      "up 1.24118 2018-02-14 16:00:28 False\n",
      "down 1.23868 2018-02-14 17:05:52 False\n",
      "up 1.24118 2018-02-14 17:43:54 False\n",
      "up 1.24368 2018-02-14 18:20:53 False\n",
      "up 1.24618 2018-02-14 20:58:34 False\n",
      "up 1.24868 2018-02-15 07:20:18 False\n",
      "down 1.24618 2018-02-15 12:20:48 False\n",
      "up 1.24868 2018-02-15 12:51:42 False\n",
      "down 1.24618 2018-02-15 17:22:41 False\n",
      "up 1.24868 2018-02-15 18:19:13 False\n",
      "up 1.25118 2018-02-16 01:55:04 False\n",
      "up 1.25368 2018-02-16 02:32:38 False\n",
      "down 1.25118 2018-02-16 10:23:28 False\n",
      "down 1.24868 2018-02-16 10:53:55 False\n",
      "down 1.24618 2018-02-16 12:25:26 False\n",
      "down 1.24368 2018-02-16 14:02:09 False\n",
      "down 1.24118 2018-02-16 18:59:21 False\n",
      "down 1.23868 2018-02-19 13:49:03 False\n",
      "up 1.24118 2018-02-19 17:52:56 False\n",
      "down 1.23868 2018-02-20 01:30:10 False\n",
      "down 1.23618 2018-02-20 07:33:47 False\n",
      "down 1.23368 2018-02-20 10:32:41 False\n",
      "down 1.23118 2018-02-21 07:32:31 False\n",
      "up 1.23368 2018-02-21 19:04:46 False\n",
      "down 1.23118 2018-02-21 19:49:43 False\n",
      "down 1.22868 2018-02-21 20:09:11 False\n",
      "down 1.22618 2018-02-22 06:53:32 False\n",
      "up 1.22868 2018-02-22 08:32:54 False\n",
      "up 1.23118 2018-02-22 13:57:49 False\n",
      "up 1.23368 2018-02-22 14:41:52 False\n",
      "down 1.23118 2018-02-23 02:56:21 False\n",
      "down 1.22868 2018-02-23 07:06:53 False\n",
      "up 1.23118 2018-02-23 08:38:10 False\n",
      "down 1.22868 2018-02-23 16:10:11 False\n",
      "up 1.23118 2018-02-26 02:30:17 False\n",
      "up 1.23368 2018-02-26 09:33:26 False\n",
      "down 1.23118 2018-02-26 13:49:56 False\n",
      "down 1.22868 2018-02-26 15:10:53 False\n",
      "up 1.23118 2018-02-26 16:22:47 False\n",
      "up 1.23368 2018-02-27 00:54:49 False\n",
      "down 1.23118 2018-02-27 13:03:19 False\n",
      "down 1.22868 2018-02-27 13:33:07 False\n",
      "up 1.23118 2018-02-27 13:38:10 False\n",
      "down 1.22868 2018-02-27 13:59:45 False\n",
      "down 1.22618 2018-02-27 15:02:50 False\n",
      "down 1.22368 2018-02-27 15:47:43 False\n",
      "down 1.22118 2018-02-28 08:09:32 False\n",
      "down 1.21868 2018-03-01 00:19:01 False\n",
      "up 1.22118 2018-03-01 07:25:21 False\n",
      "down 1.21868 2018-03-01 09:05:26 False\n",
      "down 1.21618 2018-03-01 15:00:00 False\n",
      "up 1.21868 2018-03-01 15:33:08 False\n",
      "up 1.22118 2018-03-01 16:43:34 False\n",
      "down 1.21868 2018-03-01 18:50:35 False\n",
      "up 1.22118 2018-03-01 19:23:40 False\n",
      "up 1.22368 2018-03-01 19:43:01 False\n",
      "up 1.22618 2018-03-01 20:01:53 False\n",
      "up 1.22868 2018-03-02 04:12:34 False\n",
      "down 1.22618 2018-03-02 07:00:56 False\n",
      "up 1.22868 2018-03-02 10:26:38 False\n",
      "up 1.23118 2018-03-02 11:08:01 False\n",
      "up 1.23368 2018-03-04 22:02:08 False\n",
      "up 1.23618 2018-03-04 22:15:56 False\n",
      "down 1.23368 2018-03-04 22:46:35 False\n",
      "down 1.23118 2018-03-04 23:24:53 False\n",
      "up 1.23368 2018-03-05 00:36:43 False\n",
      "down 1.23118 2018-03-05 06:18:25 False\n",
      "down 1.22868 2018-03-05 07:10:35 False\n",
      "up 1.23118 2018-03-05 08:24:34 False\n",
      "down 1.22868 2018-03-05 12:28:32 False\n",
      "up 1.23118 2018-03-05 13:27:33 False\n",
      "up 1.23368 2018-03-05 16:23:46 False\n",
      "up 1.23618 2018-03-06 01:33:05 False\n",
      "down 1.23368 2018-03-06 06:48:49 False\n",
      "up 1.23618 2018-03-06 11:23:18 False\n",
      "up 1.23868 2018-03-06 11:31:35 False\n",
      "up 1.24118 2018-03-06 12:53:02 False\n",
      "down 1.23868 2018-03-06 14:36:09 False\n",
      "up 1.24118 2018-03-06 16:06:32 False\n",
      "up 1.24368 2018-03-07 10:33:44 False\n",
      "down 1.24118 2018-03-07 11:57:29 False\n",
      "down 1.23868 2018-03-07 16:21:40 False\n",
      "up 1.24118 2018-03-07 18:44:38 False\n",
      "down 1.23868 2018-03-08 09:06:52 False\n",
      "up 1.24118 2018-03-08 12:46:19 False\n",
      "up 1.24368 2018-03-08 13:34:08 False\n",
      "down 1.24118 2018-03-08 13:46:13 False\n",
      "down 1.23868 2018-03-08 13:48:51 False\n",
      "down 1.23618 2018-03-08 14:57:07 False\n",
      "down 1.23368 2018-03-08 15:34:39 False\n",
      "down 1.23118 2018-03-08 16:47:41 False\n",
      "down 1.22868 2018-03-09 13:16:07 False\n",
      "up 1.23118 2018-03-09 13:36:24 False\n",
      "down 1.22868 2018-03-09 13:39:55 False\n",
      "up 1.23118 2018-03-09 14:58:19 False\n",
      "up 1.23368 2018-03-12 07:38:33 False\n",
      "down 1.23118 2018-03-12 09:59:56 False\n",
      "up 1.23368 2018-03-12 18:17:01 False\n",
      "up 1.23618 2018-03-13 12:32:17 False\n",
      "up 1.23868 2018-03-13 15:23:04 False\n",
      "up 1.24118 2018-03-14 05:32:00 False\n",
      "down 1.23868 2018-03-14 07:44:59 False\n",
      "down 1.23618 2018-03-14 09:49:19 False\n",
      "up 1.23868 2018-03-14 12:14:28 False\n",
      "down 1.23618 2018-03-14 13:21:00 False\n",
      "down 1.23368 2018-03-15 12:45:44 False\n",
      "down 1.23118 2018-03-15 16:45:54 False\n",
      "down 1.22868 2018-03-16 13:38:43 False\n",
      "down 1.22618 2018-03-16 14:59:03 False\n",
      "up 1.22868 2018-03-16 16:14:54 False\n",
      "down 1.22618 2018-03-19 05:43:14 False\n",
      "up 1.22868 2018-03-19 09:30:46 False\n",
      "up 1.23118 2018-03-19 12:00:17 False\n",
      "up 1.23368 2018-03-19 16:02:50 False\n",
      "down 1.23118 2018-03-20 10:00:43 False\n",
      "down 1.22868 2018-03-20 12:15:38 False\n",
      "down 1.22618 2018-03-20 16:23:44 False\n",
      "up 1.22868 2018-03-21 08:32:13 False\n",
      "down 1.22618 2018-03-21 16:09:30 False\n",
      "up 1.22868 2018-03-21 18:00:13 False\n",
      "up 1.23118 2018-03-21 18:00:26 False\n",
      "down 1.22868 2018-03-21 18:01:06 False\n",
      "down 1.22618 2018-03-21 18:01:52 False\n",
      "up 1.22868 2018-03-21 18:04:49 False\n",
      "up 1.23118 2018-03-21 18:15:03 False\n",
      "down 1.22868 2018-03-21 18:35:45 False\n",
      "up 1.23118 2018-03-21 18:45:50 False\n",
      "up 1.23368 2018-03-21 19:01:08 False\n",
      "up 1.23618 2018-03-22 00:13:39 False\n",
      "up 1.23868 2018-03-22 07:40:17 False\n",
      "down 1.23618 2018-03-22 08:31:10 False\n",
      "down 1.23368 2018-03-22 09:42:12 False\n",
      "down 1.23118 2018-03-22 10:50:11 False\n",
      "down 1.22868 2018-03-22 16:16:04 False\n",
      "up 1.23118 2018-03-22 16:28:26 False\n",
      "up 1.23368 2018-03-23 00:54:45 False\n",
      "up 1.23618 2018-03-23 15:58:49 False\n",
      "up 1.23868 2018-03-26 07:22:09 False\n",
      "up 1.24118 2018-03-26 09:39:05 False\n",
      "up 1.24368 2018-03-26 13:51:00 False\n",
      "up 1.24618 2018-03-27 06:37:00 False\n",
      "down 1.24368 2018-03-27 08:13:13 False\n",
      "down 1.24118 2018-03-27 09:55:58 False\n",
      "down 1.23868 2018-03-27 12:03:01 False\n",
      "up 1.24118 2018-03-27 15:58:20 False\n",
      "down 1.23868 2018-03-28 06:32:39 False\n",
      "down 1.23618 2018-03-28 13:22:35 False\n",
      "down 1.23368 2018-03-28 13:48:02 False\n",
      "down 1.23118 2018-03-28 18:13:35 False\n",
      "down 1.22868 2018-03-29 15:37:54 False\n",
      "up 1.23118 2018-03-30 01:54:15 False\n",
      "up 1.23368 2018-04-02 11:34:49 False\n",
      "down 1.23118 2018-04-02 14:58:42 False\n",
      "down 1.22868 2018-04-02 15:37:17 False\n",
      "up 1.23118 2018-04-03 06:07:20 False\n",
      "down 1.22868 2018-04-03 10:58:59 False\n",
      "up 1.23118 2018-04-03 12:25:54 False\n",
      "down 1.22868 2018-04-03 13:12:26 False\n",
      "down 1.22618 2018-04-03 13:19:34 False\n",
      "up 1.22868 2018-04-04 02:13:08 False\n",
      "down 1.22618 2018-04-04 07:01:20 False\n",
      "up 1.22868 2018-04-04 07:55:06 False\n",
      "up 1.23118 2018-04-04 08:11:55 False\n",
      "down 1.22868 2018-04-04 09:52:47 False\n",
      "down 1.22618 2018-04-05 06:24:54 False\n",
      "down 1.22368 2018-04-05 12:30:18 False\n",
      "up 1.22618 2018-04-05 12:43:06 False\n",
      "down 1.22368 2018-04-05 14:29:00 False\n",
      "up 1.22618 2018-04-06 13:10:54 False\n",
      "up 1.22868 2018-04-06 18:01:55 False\n",
      "down 1.22618 2018-04-09 07:02:22 False\n",
      "up 1.22868 2018-04-09 12:06:04 False\n",
      "up 1.23118 2018-04-09 12:49:18 False\n",
      "up 1.23368 2018-04-10 11:31:04 False\n",
      "up 1.23618 2018-04-10 11:31:39 False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "stateData = connection.execute(db2.select([state_table])).fetchall()\n",
    "\n",
    "if len(stateData)==0:\n",
    "    id=0\n",
    "    chart = Chart()    \n",
    "else:\n",
    "    row = stateData[0]\n",
    "    id=row[0]\n",
    "    chart = Chart(brick_size=row[1], brick_price=row[2], previous_timestamp=row[3], previous_brick_timestamp=row[4], crossover_brick=row[5])\n",
    "\n",
    "print(\"starting from {}\".format(id))\n",
    "\n",
    "while id < total_line_count+1:\n",
    "    id+=1\n",
    "    sql = \"SELECT * FROM price WHERE id = %s\"\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql, (id, ) )\n",
    "    row = cursor.fetchone()\n",
    "    cursor.close()\n",
    "    \n",
    "    price = row[1]\n",
    "    timestamp = row[2]\n",
    "    \n",
    "#     print('\\r{} {}'.format(price, timestamp), end=' ')\n",
    "#     print('{} {}\\r'.format(price, timestamp), end='')\n",
    "    chart.feed(id, price, timestamp)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
